recursive = TRUE)
# From that list, get site names
dir_length <- lengths(strsplit(dir_list, "/"))
dir_years <- dir_list[grepl("/\\d{4}$", dir_list)] # directories ending with a year.
dir_sites <- list.dirs(dir_years, full.names = TRUE, recursive = FALSE)
sites <- unique(sapply(strsplit(dir_sites, "/"), '[[', length(strsplit(dir_sites, "/")[[1]])))
# load all necessary functions
fx_path <- paste0(arg,'functions',sep ="")
p <- sapply(list.files(fx_path,pattern="*.R$", full.names=TRUE), source)
# 2. LOAD DATA -----
# Load site data from first site when app initializes
site <- sites[1]
# Find which years are available
yrs <- yrs_included(basepath,site,level[1])
data <- read_data_all_years(basepath,yrs,site,level,tv_input)
data_units <- var_units(colnames(data),UnitCSVFilePath)
# CREATE DATASET TO PLOT ALL SITES AT ONCE
# Only a few variables
var_of_interest <- c('datetime',
'FC', 'FCH4', # Ecosystem productivity and C fluxes
'VPD', 'RH',  'TA', 'PPFD_IN', 'SW_IN', # Meteorological variables
'USTAR', # Atmospheric stability / roughness length approximation (proxy for 'good' EC conditions)
'LE','H', 'NETRAD', 'G' # Surface energy balance
)
data_all <- data.frame()
# Loop through all sites to create a dataframe with data from all sites
for (i in 1:length(sites)) {
# Open data at site
site <- sites[i]
yrs <- yrs_included(basepath,site,level)
# Load data
data_in <- read_data_all_years(basepath,yrs,site,level,tv_input)
cols <- colnames(data_in) # Get column names
# remove HVR qualifiers
vars <- gsub("_[[:digit:]]", "", cols)
colnames(data_in) <- vars
# Create empty column for missing variables of interest
data_in[var_of_interest[!(var_of_interest %in% vars)]] = NA
# Get index of each column of variable of interest
indexvar <- c()
for (j in 1:length(var_of_interest)) {
indexvar[j] <- which(names(data_in) %in% var_of_interest[j])
}
indexvar <- na.omit(indexvar)
data_subset <- data_in[,indexvar]
# Add 'site' variable to dataframe
data_subset$site <- site
# Merge with other sites
if (i == 1){
data_all <- data_subset
} else {data_all <- merge(data_all, data_subset, all = T)
}
print(unique(data_subset$site))
}
# Define units for plot with all sites
data_units_all <- var_units(colnames(data_all),UnitCSVFilePath)
# X variable names (all sites)
xvars <- var_of_interest
# Y variable names (all sites)
yvars <- var_of_interest[-length(var_of_interest)]
# Load site coordinates
sites_coordinates <- read_excel(coordinatesXLSXFilePath,sheet=1,col_names= TRUE)
# save data to app folder
save(list = ls(), file = paste0(arg,'data_tmp/all_data.RData',sep =""))
j
which(names(data_in) %in% var_of_interest[j])
names(data_in)
var_of_interest
j
j = 13
indexvar <- c()
for (j in 1:length(var_of_interest)) {
indexvar[j] <- which(names(data_in) %in% var_of_interest[j])
}
indexvar
site
i = 1
site <- sites[i]
yrs <- yrs_included(basepath,site,level)
# Load data
data_in <- read_data_all_years(basepath,yrs,site,level,tv_input)
cols <- colnames(data_in) # Get column names
# remove HVR qualifiers
vars <- gsub("_[[:digit:]]", "", cols)
colnames(data_in) <- vars
# Create empty column for missing variables of interest
data_in[var_of_interest[!(var_of_interest %in% vars)]] = NA
# Get index of each column of variable of interest
indexvar <- c()
for (j in 1:length(var_of_interest)) {
indexvar[j] <- which(names(data_in) %in% var_of_interest[j])
}
indexvar <- na.omit(indexvar)
data_subset <- data_in[,indexvar]
j = 2
i = 1
j = 1
site <- sites[i]
yrs <- yrs_included(basepath,site,level)
# Load data
data_in <- read_data_all_years(basepath,yrs,site,level,tv_input)
cols <- colnames(data_in) # Get column names
# remove HVR qualifiers
vars <- gsub("_[[:digit:]]", "", cols)
colnames(data_in) <- vars
# Create empty column for missing variables of interest
data_in[var_of_interest[!(var_of_interest %in% vars)]] = NA
# Get index of each column of variable of interest
indexvar <- c()
for (j in 1:length(var_of_interest)) {
indexvar[j] <- which(names(data_in) %in% var_of_interest[j])
}
indexvar <- na.omit(indexvar)
data_subset <- data_in[,indexvar]
# Add 'site' variable to dataframe
data_subset$site <- site
j = 3
i = 3
j = 1
site <- sites[i]
yrs <- yrs_included(basepath,site,level)
# Load data
data_in <- read_data_all_years(basepath,yrs,site,level,tv_input)
cols <- colnames(data_in) # Get column names
# remove HVR qualifiers
vars <- gsub("_[[:digit:]]", "", cols)
colnames(data_in) <- vars
# Create empty column for missing variables of interest
data_in[var_of_interest[!(var_of_interest %in% vars)]] = NA
# Get index of each column of variable of interest
indexvar <- c()
for (j in 1:length(var_of_interest)) {
indexvar[j] <- which(names(data_in) %in% var_of_interest[j])
}
indexvar <- na.omit(indexvar)
data_subset <- data_in[,indexvar]
indexvar
packages <- c("ggplot2", "dplyr", "shiny", "patchwork", "plotly", "gapminder", "shinycssloaders", "readxl", "stringi", "shinythemes", "cowplot",
"imager", "naniar", "GGally", "shinydashboard", "tidyr", "tibble", "epitools", "lubridate", "hms", "forecast", "reshape2",
"stringr", "data.table", "ggpmisc", "ggrepel")
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
# Packages loading
invisible(lapply(packages, library, character.only = TRUE))
# reactiveConsole(T) # allows the csv file to be used properly
# “install.packages(“igraph”, type=“binary”) - uncomment if receiving a “there is no package called ‘igraph’” error when loading imager
# for imager may need to download quartz to be able to run this library properly (https://www.xquartz.org) & may need to use install.packages("igraph", type="binary")
# List all directories and subdirectories
dir_list <- list.dirs(main_dir,full.names = TRUE,
recursive = TRUE)
source("/Users/saraknox/Code/local_data_cleaning/Projects/EcoFlux/Database/Calculation_Procedures/RShiny_flux_plots_ini/EcoFlux_ini.R")
packages <- c("ggplot2", "dplyr", "shiny", "patchwork", "plotly", "gapminder", "shinycssloaders", "readxl", "stringi", "shinythemes", "cowplot",
"imager", "naniar", "GGally", "shinydashboard", "tidyr", "tibble", "epitools", "lubridate", "hms", "forecast", "reshape2",
"stringr", "data.table", "ggpmisc", "ggrepel")
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
# Packages loading
invisible(lapply(packages, library, character.only = TRUE))
# reactiveConsole(T) # allows the csv file to be used properly
# “install.packages(“igraph”, type=“binary”) - uncomment if receiving a “there is no package called ‘igraph’” error when loading imager
# for imager may need to download quartz to be able to run this library properly (https://www.xquartz.org) & may need to use install.packages("igraph", type="binary")
# List all directories and subdirectories
dir_list <- list.dirs(main_dir,full.names = TRUE,
recursive = TRUE)
# From that list, get site names
dir_length <- lengths(strsplit(dir_list, "/"))
dir_years <- dir_list[grepl("/\\d{4}$", dir_list)] # directories ending with a year.
dir_sites <- list.dirs(dir_years, full.names = TRUE, recursive = FALSE)
sites <- unique(sapply(strsplit(dir_sites, "/"), '[[', length(strsplit(dir_sites, "/")[[1]])))
# load all necessary functions
fx_path <- paste0(arg,'functions',sep ="")
p <- sapply(list.files(fx_path,pattern="*.R$", full.names=TRUE), source)
# 2. LOAD DATA -----
# Load site data from first site when app initializes
site <- sites[1]
# Find which years are available
yrs <- yrs_included(basepath,site,level[1])
data <- read_data_all_years(basepath,yrs,site,level,tv_input)
data_units <- var_units(colnames(data),UnitCSVFilePath)
# CREATE DATASET TO PLOT ALL SITES AT ONCE
# Only a few variables
var_of_interest <- c('datetime',
'FC', 'FCH4', # Ecosystem productivity and C fluxes
'VPD', 'RH',  'TA', 'PPFD_IN', 'SW_IN', # Meteorological variables
'USTAR', # Atmospheric stability / roughness length approximation (proxy for 'good' EC conditions)
'LE','H', 'NETRAD', 'G' # Surface energy balance
)
data_all <- data.frame()
# Loop through all sites to create a dataframe with data from all sites
for (i in 1:length(sites)) {
# Open data at site
site <- sites[i]
yrs <- yrs_included(basepath,site,level)
# Load data
data_in <- read_data_all_years(basepath,yrs,site,level,tv_input)
cols <- colnames(data_in) # Get column names
# remove HVR qualifiers
vars <- gsub("_[[:digit:]]", "", cols)
colnames(data_in) <- vars
# Create empty column for missing variables of interest
data_in[var_of_interest[!(var_of_interest %in% vars)]] = NA
# Get index of each column of variable of interest
indexvar <- c()
for (j in 1:length(var_of_interest)) {
indexvar[j] <- which(names(data_in) %in% var_of_interest[j])
}
indexvar <- na.omit(indexvar)
data_subset <- data_in[,indexvar]
# Add 'site' variable to dataframe
data_subset$site <- site
# Merge with other sites
if (i == 1){
data_all <- data_subset
} else {data_all <- merge(data_all, data_subset, all = T)
}
print(unique(data_subset$site))
}
print(unique(data_subset$site))
i
source("/Users/saraknox/Code/local_data_cleaning/Projects/EcoFlux/Database/Calculation_Procedures/RShiny_flux_plots_ini/EcoFlux_ini.R")
# Package names
packages <- c("ggplot2", "dplyr", "shiny", "patchwork", "plotly", "gapminder", "shinycssloaders", "readxl", "stringi", "shinythemes", "cowplot",
"imager", "naniar", "GGally", "shinydashboard", "tidyr", "tibble", "epitools", "lubridate", "hms", "forecast", "reshape2",
"stringr", "data.table", "ggpmisc", "ggrepel")
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
# Packages loading
invisible(lapply(packages, library, character.only = TRUE))
# reactiveConsole(T) # allows the csv file to be used properly
# “install.packages(“igraph”, type=“binary”) - uncomment if receiving a “there is no package called ‘igraph’” error when loading imager
# for imager may need to download quartz to be able to run this library properly (https://www.xquartz.org) & may need to use install.packages("igraph", type="binary")
# List all directories and subdirectories
dir_list <- list.dirs(main_dir,full.names = TRUE,
recursive = TRUE)
# From that list, get site names
dir_length <- lengths(strsplit(dir_list, "/"))
dir_years <- dir_list[grepl("/\\d{4}$", dir_list)] # directories ending with a year.
dir_sites <- list.dirs(dir_years, full.names = TRUE, recursive = FALSE)
sites <- unique(sapply(strsplit(dir_sites, "/"), '[[', length(strsplit(dir_sites, "/")[[1]])))
# load all necessary functions
fx_path <- paste0(arg,'functions',sep ="")
p <- sapply(list.files(fx_path,pattern="*.R$", full.names=TRUE), source)
# 2. LOAD DATA -----
# Load site data from first site when app initializes
site <- sites[1]
# Find which years are available
yrs <- yrs_included(basepath,site,level[1])
data <- read_data_all_years(basepath,yrs,site,level,tv_input)
data_units <- var_units(colnames(data),UnitCSVFilePath)
# CREATE DATASET TO PLOT ALL SITES AT ONCE
# Only a few variables
var_of_interest <- c('datetime',
'FC', 'FCH4', # Ecosystem productivity and C fluxes
'VPD', 'RH',  'TA', 'PPFD_IN', 'SW_IN', # Meteorological variables
'USTAR', # Atmospheric stability / roughness length approximation (proxy for 'good' EC conditions)
'LE','H', 'NETRAD', 'G' # Surface energy balance
)
data_all <- data.frame()
# Loop through all sites to create a dataframe with data from all sites
for (i in 1:length(sites)) {
# Open data at site
site <- sites[i]
yrs <- yrs_included(basepath,site,level)
# Load data
data_in <- read_data_all_years(basepath,yrs,site,level,tv_input)
cols <- colnames(data_in) # Get column names
# remove HVR qualifiers
vars <- gsub("_[[:digit:]]", "", cols)
colnames(data_in) <- vars
# Create empty column for missing variables of interest
data_in[var_of_interest[!(var_of_interest %in% vars)]] = NA
# Get index of each column of variable of interest
indexvar <- c()
k <- 0
for (j in 1:length(var_of_interest)) {
k <- k+1
indexvar[k] <- which(names(data_in) %in% var_of_interest[j])
}
indexvar <- na.omit(indexvar)
data_subset <- data_in[,indexvar]
# Add 'site' variable to dataframe
data_subset$site <- site
# Merge with other sites
if (i == 1){
data_all <- data_subset
} else {data_all <- merge(data_all, data_subset, all = T)

}
print(unique(data_subset$site))
}

# Define units for plot with all sites
data_units_all <- var_units(colnames(data_all),UnitCSVFilePath)
# X variable names (all sites)
xvars <- var_of_interest
# Y variable names (all sites)
yvars <- var_of_interest[-length(var_of_interest)]
# Load site coordinates
sites_coordinates <- read_excel(coordinatesXLSXFilePath,sheet=1,col_names= TRUE)
# save data to app folder
save(list = ls(), file = paste0(arg,'data_tmp/all_data.RData',sep =""))
runApp('RShiny_flux_plots.R')
source("/Users/saraknox/Code/local_data_cleaning/Projects/EcoFlux/Database/Calculation_Procedures/RShiny_flux_plots_ini/UQAM_ini.R")
source("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/load_save_data.R")
shiny::runApp("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/RShiny_flux_plots.R") # Run 'RShiny_flux_plots.Rd' and include your local path to the file.
75/15
source("/Users/saraknox/Code/local_data_cleaning/Projects/EcoFlux/Database/Calculation_Procedures/RShiny_flux_plots_ini/TUT_ini.R")
source("/Users/saraknox/Code/local_data_cleaning/Projects/TUT/Database/Calculation_Procedures/RShiny_flux_plots_ini/TUT_ini.R")
source("/Users/saraknox/Code/local_data_cleaning/Projects/TUT/Database/Calculation_Procedures/RShiny_flux_plots_ini/TUT_RShiny_ini.R")
source("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/load_save_data.R")
shiny::runApp("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/RShiny_flux_plots.R") # Run 'RShiny_flux_plots.Rd' and include your local path to the file.
# variables/paths to edit to run 'flux_shiny_app.R'
# Specify the path to your database
main_dir <- "/Users/saraknox/Code/local_data_cleaning/Projects/TUT/Database"
# Path for met/flux variables to display
basepath <- main_dir
level <- c("Clean/ThirdStage") # Can load data from one or multiple folders/sub-folders. Here is an example for load data from two folders
tv_input <- "clean_tv" # MAKE SURE tv is in folder - this can sometimes generate an error.
# Specify the path to csv file with units
UnitCSVFilePath <- '/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/flux_variables.csv'
# Specify the path to shiny app
arg <- '/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/'
# provide names for incoming shortwave radiation and incoming PPDF
var_rad <- c('SW_IN_1_1_1', 'PPFD_IN_1_1_1')
# path and file name of site coordinates - you will need to DOWNLOAD and EDIT this file the first time.
# This file will be under your ./Calculation_Procedures/RShiny_flux_plots_ini folder that you created
# Note that the standard meridian is = to your UTC offet (without daylight savings) x 15 (e.g., Montreal is UTC-5 so the standard meridian is -75)
# Also note that latitude and longitude are in decimal degrees and negative for West and South coordinates
coordinatesXLSXFilePath <- '/Users/saraknox/Code/local_data_cleaning/Projects/TUT/Database/Calculation_Procedures/RShiny_flux_plots_ini/site_coordinates_TUT.xlsx'
source("/Users/saraknox/Code/local_data_cleaning/Projects/TUT/Database/Calculation_Procedures/RShiny_flux_plots_ini/TUT_RShiny_ini.R")
source("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/load_save_data.R")
shiny::runApp("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/RShiny_flux_plots.R") # Run 'RShiny_flux_plots.Rd' and include your local path to the file.
source("/Users/saraknox/Code/local_data_cleaning/Projects/TUT/Database/Calculation_Procedures/RShiny_flux_plots_ini/TUT_RShiny_ini.R")
source("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/load_save_data.R")
View(data)
source("/Users/saraknox/Code/local_data_cleaning/Projects/TUT/Database/Calculation_Procedures/RShiny_flux_plots_ini/TUT_RShiny_ini.R")
source("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/load_save_data.R")
shiny::runApp("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/RShiny_flux_plots.R") # Run 'RShiny_flux_plots.Rd' and include your local path to the file.
source("/Users/saraknox/Code/local_data_cleaning/Projects/EcoFlux/Database/Calculation_Procedures/RShiny_flux_plots_ini/UQAM_ini.R")
source("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/load_save_data.R")
shiny::runApp("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/RShiny_flux_plots.R") # Run 'RShiny_flux_plots.Rd' and include your local path to the file.
source("/Users/saraknox/Code/local_data_cleaning/Projects/EcoFlux/Database/Calculation_Procedures/RShiny_flux_plots_ini/EcoFlux_ini.R")
source("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/load_save_data.R")
shiny::runApp("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/RShiny_flux_plots.R") # Run 'RShiny_flux_plots.Rd' and include your local path to the file.
source("/Users/saraknox/Code/local_data_cleaning/Projects/EcoFlux/Database/Calculation_Procedures/RShiny_flux_plots_ini/UQAM_ini.R")
source("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/load_save_data.R")
shiny::runApp("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/RShiny_flux_plots.R") # Run 'RShiny_flux_plots.Rd' and include your local path to the file.
sites
radcol <- var_rad
rad_name <- radcol # Get name of variable selected
#ylabel <- rad_names # Could update this
# Rename variables to remove variable prefix
df <- selectedDataRadiation()
# Rename variables to remove variable prefix
df <- data[, c("datetime",radcol)]
head(df)
names(df) <- sub(paste0('^',rad_name,'.'), '', names(df))
# Calculate potential radiation
sites_coordinates_filtered <-  sites_coordinates[sites_coordinates['Site'] == sites, ] # extra standard meridian/lat/long from excel file
df$pot_rad <- potential_rad_generalized(as.numeric(sites_coordinates_filtered$Standard_Meridian), as.numeric(sites_coordinates_filtered$Longitude), as.numeric(sites_coordinates_filtered$Latitude), df$datetime,yday(df$datetime))
sites_coordinates_filtered <-  sites_coordinates[sites_coordinates['Site'] == sites, ] # extra standard meridian/lat/long from excel file
sites_coordinates_filtered
source("/Users/saraknox/Code/local_data_cleaning/Projects/EcoFlux/Database/Calculation_Procedures/RShiny_flux_plots_ini/UQAM_ini.R")
source("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/load_save_data.R")
shiny::runApp("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/RShiny_flux_plots.R") # Run 'RShiny_flux_plots.Rd' and include your local path to the file.
source("/Users/saraknox/Code/local_data_cleaning/Projects/TUT/Database/Calculation_Procedures/RShiny_flux_plots_ini/TUT_RShiny_ini.R")
source("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/load_save_data.R")
shiny::runApp("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/RShiny_flux_plots.R") # Run 'RShiny_flux_plots.Rd' and include your local path to the file.
# Package names
packages <- c("tidyverse", "ranger", "caret", "ggplot2")
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
# Package names
packages <- c("tidyverse", "caret")
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
# Package names
packages <- c("REddyProc", "dplyr", "lubridate", "data.table")
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
packages <- c("fs", "yaml", "REddyProc", "rlist", "zoo", "dplyr", "lubridate", "data.table", "reshape2", "stringr", "tidyverse", "ranger", "caret", "ggplot2")
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
source("/Users/saraknox/Code/local_data_cleaning/Projects/TUT/Database/Calculation_Procedures/TUT/TUT_RShiny_ini.R")

# variables/paths to edit to run 'flux_shiny_app.R'
# Specify the path to your database
main_dir <- "/Users/saraknox/Code/local_data_cleaning/Projects/TUT/Database"
# Path for met/flux variables to display
basepath <- main_dir
level <- c("Clean/ThirdStage") # Can load data from one or multiple folders/sub-folders. Here is an example for load data from two folders
tv_input <- "clean_tv" # MAKE SURE tv is in folder - this can sometimes generate an error.
# Specify the path to csv file with units
UnitCSVFilePath <- '/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/flux_variables.csv'
# Specify the path to shiny app
arg <- '/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/'
# provide names for incoming shortwave radiation and incoming PPDF
var_rad <- c('SW_IN_1_1_1')
# path and file name of site coordinates - you will need to DOWNLOAD and EDIT this file the first time.
# This file will be under your ./Calculation_Procedures/RShiny_flux_plots_ini folder that you created
# Note that the standard meridian is = to your UTC offet (without daylight savings) x 15 (e.g., Montreal is UTC-5 so the standard meridian is -75)
# Also note that latitude and longitude are in decimal degrees and negative for West and South coordinates
coordinatesXLSXFilePath <- '/Users/saraknox/Code/local_data_cleaning/Projects/TUT/Database/Calculation_Procedures/TraceAnalysis_ini/TUT/site_coordinates_TUT.xlsx'
source("/Users/saraknox/Code/local_data_cleaning/Projects/TUT/Database/Calculation_Procedures/TraceAnalysis_ini/TUT/TUT_RShiny_ini.R")
source("/Users/saraknox/Code/local_data_cleaning/Projects/TUT/Database/Calculation_Procedures/TraceAnalysis_ini/TUT/TUT_RShiny_ini.R")
source("/Users/saraknox/Code/local_data_cleaning/Projects/TUT/Database/Calculation_Procedures/TraceAnalysis_ini/TUT/TUT_RShiny_ini.R")
source("/Users/saraknox/Code/local_data_cleaning/Projects/My_Micromet/Database/Calculation_Procedures/TraceAnalysis_ini/TUT/TUT_RShiny_ini.R")
source("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/load_save_data.R")
source("/Users/saraknox/Code/local_data_cleaning/Projects/My_Micromet/Database/Calculation_Procedures/TraceAnalysis_ini/TUT/TUT_RShiny_ini.R")
source("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/load_save_data.R")
source("/Users/saraknox/Code/local_data_cleaning/Projects/My_Micromet/Database/Calculation_Procedures/TraceAnalysis_ini/TUT/TUT_RShiny_ini.R")
source("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/load_save_data.R")
source("/Users/saraknox/Code/local_data_cleaning/Projects/My_Micromet/Database/Calculation_Procedures/TraceAnalysis_ini/TUT/TUT_RShiny_ini.R")
# Package names
packages <- c("ggplot2", "dplyr", "shiny", "patchwork", "plotly", "gapminder", "shinycssloaders", "readxl", "stringi", "shinythemes", "cowplot",
"imager", "naniar", "GGally", "shinydashboard", "tidyr", "tibble", "epitools", "lubridate", "hms", "forecast", "reshape2",
"stringr", "data.table", "ggpmisc", "ggrepel")
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
# Packages loading
invisible(lapply(packages, library, character.only = TRUE))
# reactiveConsole(T) # allows the csv file to be used properly
# “install.packages(“igraph”, type=“binary”) - uncomment if receiving a “there is no package called ‘igraph’” error when loading imager
# for imager may need to download quartz to be able to run this library properly (https://www.xquartz.org) & may need to use install.packages("igraph", type="binary")
# List all directories and subdirectories
dir_list <- list.dirs(main_dir,full.names = TRUE,
recursive = TRUE)
# From that list, get site names
dir_length <- lengths(strsplit(dir_list, "/"))
dir_years <- dir_list[grepl("/\\d{4}$", dir_list)] # directories ending with a year.
dir_sites <- list.dirs(dir_years, full.names = TRUE, recursive = FALSE)
sites <- unique(sapply(strsplit(dir_sites, "/"), '[[', length(strsplit(dir_sites, "/")[[1]])))
# load all necessary functions
fx_path <- paste0(arg,'functions',sep ="")
p <- sapply(list.files(fx_path,pattern="*.R$", full.names=TRUE), source)
# 2. LOAD DATA -----
# Load site data from first site when app initializes
site <- sites[1]
# Find which years are available
yrs <- yrs_included(basepath,site,level[1])
data <- read_data_all_years(basepath,yrs,site,level,tv_input)
main_dir
dir_list
dir_list <- list.dirs(main_dir,full.names = TRUE,
recursive = TRUE)
dir_list
source("/Users/saraknox/Code/local_data_cleaning/Projects/My_Micromet/Database/Calculation_Procedures/TraceAnalysis_ini/TUT/TUT_RShiny_ini.R")
source("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/load_save_data.R")
source("/Users/saraknox/Code/local_data_cleaning/Projects/My_Micromet/Database/Calculation_Procedures/TraceAnalysis_ini/TUT/TUT_RShiny_ini.R")
source("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/load_save_data.R")
# variables/paths to edit to run 'flux_shiny_app.R'
# Specify the path to your database
main_dir <- "/Users/saraknox/Code/local_data_cleaning/Projects/My_Micromet/Database"

# Path for met/flux variables to display
basepath <- main_dir
level <- c("Clean/ThirdStage") # Can load data from one or multiple folders/sub-folders. Here is an example for load data from two folders
tv_input <- "clean_tv" # MAKE SURE tv is in folder - this can sometimes generate an error.
# Specify the path to csv file with units
UnitCSVFilePath <- '/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/flux_variables.csv'
# Specify the path to shiny app
arg <- '/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/'
# provide names for incoming shortwave radiation and incoming PPDF
var_rad <- c('SW_IN_1_1_1')
# path and file name of site coordinates - you will need to DOWNLOAD and EDIT this file the first time.
# This file will be under your ./Calculation_Procedures/RShiny_flux_plots_ini folder that you created
# Note that the standard meridian is = to your UTC offet (without daylight savings) x 15 (e.g., Montreal is UTC-5 so the standard meridian is -75)
# Also note that latitude and longitude are in decimal degrees and negative for West and South coordinates

coordinatesXLSXFilePath <- '/Users/saraknox/Code/local_data_cleaning/Projects/My_Micromet/Database/Calculation_Procedures/TraceAnalysis_ini/TUT/site_coordinates_TUT.xlsx'
source("/Users/saraknox/Code/local_data_cleaning/Projects/My_Micromet/Database/Calculation_Procedures/TraceAnalysis_ini/TUT/TUT_RShiny_ini.R")

packages <- c("ggplot2", "dplyr", "shiny", "patchwork", "plotly", "gapminder", "shinycssloaders", "readxl", "stringi", "shinythemes", "cowplot",
"imager", "naniar", "GGally", "shinydashboard", "tidyr", "tibble", "epitools", "lubridate", "hms", "forecast", "reshape2",
"stringr", "data.table", "ggpmisc", "ggrepel")
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
install.packages(packages[!installed_packages])
}
# Packages loading
invisible(lapply(packages, library, character.only = TRUE))
# reactiveConsole(T) # allows the csv file to be used properly
# “install.packages(“igraph”, type=“binary”) - uncomment if receiving a “there is no package called ‘igraph’” error when loading imager
# for imager may need to download quartz to be able to run this library properly (https://www.xquartz.org) & may need to use install.packages("igraph", type="binary")
# List all directories and subdirectories
dir_list <- list.dirs(main_dir,full.names = TRUE,
recursive = TRUE)

dir_list
main_dir
main_dir
source("/Users/saraknox/Code/local_data_cleaning/Projects/My_Micromet/Database/Calculation_Procedures/TraceAnalysis_ini/TUT/TUT_RShiny_ini.R")
source("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/load_save_data.R")
shiny::runApp("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/RShiny_flux_plots.R") # Run 'RShiny_flux_plots.Rd' and include your local path to the file.
source("/Users/saraknox/Code/local_data_cleaning/Projects/EcoFlux/Database/Calculation_Procedures/RShiny_flux_plots_ini/UQAM_ini.R")
source("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/load_save_data.R")
source("/Users/saraknox/Code/local_data_cleaning/Projects/EcoFlux/Database/Calculation_Procedures/RShiny_flux_plots_ini/EcoFlux_ini.R")
source("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/load_save_data.R")
shiny::runApp("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/RShiny_flux_plots.R") # Run 'RShiny_flux_plots.Rd' and include your local path to the file.
source("/Users/saraknox/Code/local_data_cleaning/Projects/EcoFlux/Database/Calculation_Procedures/RShiny_flux_plots_ini/EcoFlux_ini.R")
source("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/load_save_data.R")
shiny::runApp("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/RShiny_flux_plots.R") # Run 'RShiny_flux_plots.Rd' and include your local path to the file.
source("/Users/saraknox/Code/local_data_cleaning/Projects/EcoFlux/Database/Calculation_Procedures/RShiny_flux_plots_ini/EcoFlux_ini.R")
source("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/load_save_data.R")
shiny::runApp("/Users/saraknox/Code/Biomet.net/R/RShiny_flux_plots/RShiny_flux_plots.R") # Run 'RShiny_flux_plots.Rd' and include your local path to the file.
i
sites[i]
yrs <- yrs_included(basepath,site,level)
yrs
# Load data
data_in <- read_data_all_years(basepath,yrs,site,level,tv_input)
cols <- colnames(data_in) # Get column names
# remove HVR qualifiers
vars <- gsub("_[[:digit:]]", "", cols)
colnames(data_in) <- vars
# Create empty column for missing variables of interest
data_in[var_of_interest[!(var_of_interest %in% vars)]] = NA
# Get index of each column of variable of interest
indexvar <- c()
k <- 0
for (j in 1:length(var_of_interest)) {
k <- k+1
indexvar[k] <- which(names(data_in) %in% var_of_interest[j])
}
indexvar <- na.omit(indexvar)
data_subset <- data_in[,indexvar]
# Add 'site' variable to dataframe
data_subset$site <- site
# Merge with other sites
if (i == 1){
data_all <- data_subset
} else {data_all <- merge(data_all, data_subset, all = T)
}
# Merge with other sites
if (i == 1){
data_all <- data_subset
} else {data_all <- merge(data_all, data_subset, all = T)
}
print(unique(data_subset$site))
}

