library(stringr)
library(lubridate)
# Find which years are available
dir_yrs_sites <- dir_sites[grepl(site, dir_sites) == TRUE]
yrs <- unique(sapply(strsplit(dir_yrs_sites, "/"), '[[', 7))
# Loop through years
for (i in 1:length(yrs)) {
inpath <-
paste(basepath,
"/",
as.character(yrs[i]),
"/",
site,
"/",
level[1],
sep = "")
#setwd()
#Convert Matlab timevector to POSIXct
tv <- readBin(paste0(inpath,"/",tv_input,sep=""), double(), n = 18000)
datetime <-
as.POSIXct((tv - 719529) * 86400, origin = "1970-01-01", tz = "UTC")
# Round to nearest 30 min
datetime <- lubridate::round_date(datetime, "30 minutes")
#setup empty dataframe
frame <- data.frame(matrix(ncol = 1, nrow = length(datetime)))
# Loop through levels
for (j in 1:length(level)) {
inpath <-
paste(basepath,
"/",
as.character(yrs[i]),
"/",
site,
"/",
level[j],
sep = "")
#Extract data of interest
##Use a loop function to read selected binary files and bind to the empty dataframe
# if variables not defined
if( !is.null("variables") )
{
variables <- list.files(paste0(inpath,"/"))
}
for (k in 1:length(variables)) {
if (variables[k] %in% list.files(inpath)) {
# If the variable is included in the current level
# Skip the data_EP.txt file
if (grepl(".txt$", variables[k])) next
if (grepl("clean_tv", variables[k])) next
data <-
data.frame(readBin(paste0(inpath,"/",variables[k],sep=""), numeric(), n = 18000, size = 4))
colnames(data) <- variables[k]
frame <- cbind(frame, data)
}
}
}
df <-
subset(frame, select = -c(1)) #remove the first column that does not contain information
df <- cbind(datetime, df) #Combine data with datetime
# Make sure all input variables are included in the dataframe
if (sum(which(variables %in% colnames(df) == FALSE)) > 0) {
cat("variables: ", variables[which(variables %in% colnames(df) == FALSE)],"are not included in the dataframe", sep="\n")
}
if (i == 1) {
empty_df = df[FALSE, ]
dfmultiyear <- rbind(empty_df, df)
} else {
dfmultiyear <- rbind(dfmultiyear, df)
}
}
if( !is.null("export") ){
export <- 0
}
if (export == 1) {
write.csv(df, paste(outpath, outfilename, ".csv", sep = ""))
}
return(dfmultiyear)
}
var_units <- function(Variables, UnitCSVFilePath) {
# -------------------------------------------------------------------------- #
# ARGUMENTS:
# - Variables [list]: list of variable names
# - UnitCSVFilePath [str]: A string that contains the path to an AmeriFlux
#   CSV
# PURPOSE:
# - matches user-inputted variables to their AmeriFlux Variable and Units
#   counterparts.
# OUTPUT:
# - returns a dataframe containing the AmeriFlux Varaibles and Units data
#   adhering to the user-inputted csv's.
# -------------------------------------------------------------------------- #
shortnames <- sapply(strsplit(Variables, split = "(_[0-9])"), '[',1)
shortnames <- sapply(strsplit(shortnames, split = "_PI"),'[',1)
units <- data.frame(name = Variables,
variable = shortnames)
flux_var <- read.csv(UnitCSVFilePath)
flux_var <- flux_var[, c('Variable',
'Units',
'Type')]
for (i in 1:length(units$variable)) {
units$variable[i] <- stringr::str_to_upper(units$variable[i])
}
data_units <- vector(mode='character',length=length(units$variable))
for (i in 1:length(units$variable)) {
if (length(which(flux_var$Variable %in% units$variable[i])) > 0) {
ind <- which(flux_var$Variable %in% units$variable[i])
data_units[i] <- flux_var$Units[ind]
}
}
units$data_units <- data_units
return(units)
}
# 3. LOAD DATA -----
# Load site data from first site when app initalizies
site <- sites[1]
data <- read_data_all_years(basepath,site,level,tv_input)
data_units <- var_units(colnames(data),UnitCSVFilePath)
head(data_units)
selectedData <- data[, "FC_1_1_1"]
selectedData <- data[, 'FC']
names(selectedData
)
dat_names <- 'FC'
data_units$name
paste0(dat_names, ' (', data_units[which(data_units$name == dat_names)], ')'
)
ylabel <- paste0(dat_names, ' (', data_units[which(data_units$name == dat_names)], ')')
data_units[which(data_units$name == dat_names)]
data_units$name
dat_names
which(data_units$name == dat_names)
data_units[which(data_units$name == dat_names)]
data_units$name[which(data_units$name == dat_names)]
ylabel <- paste0(dat_names, ' (', data_units$name[which(data_units$name == dat_names)], ')')
ylabel
View(data_units)
var_units <- function(Variables, UnitCSVFilePath) {
# -------------------------------------------------------------------------- #
# ARGUMENTS:
# - Variables [list]: list of variable names
# - UnitCSVFilePath [str]: A string that contains the path to an AmeriFlux
#   CSV
# PURPOSE:
# - matches user-inputted variables to their AmeriFlux Variable and Units
#   counterparts.
# OUTPUT:
# - returns a dataframe containing the AmeriFlux Varaibles and Units data
#   adhering to the user-inputted csv's.
# -------------------------------------------------------------------------- #
shortnames <- sapply(strsplit(Variables, split = "(_[0-9])"), '[',1)
shortnames <- sapply(strsplit(shortnames, split = "_PI"),'[',1)
units <- data.frame(name = Variables,
variable = shortnames)
flux_var <- read.csv(UnitCSVFilePath)
flux_var <- flux_var[, c('Variable',
'Units',
'Type')]
for (i in 1:length(units$variable)) {
units$variable[i] <- stringr::str_to_upper(units$variable[i])
}
data_units <- vector(mode='character',length=length(units$variable))
for (i in 1:length(units$variable)) {
if (length(which(flux_var$Variable %in% units$variable[i])) > 0) {
ind <- which(flux_var$Variable %in% units$variable[i])
data_units[i] <- flux_var$Units[ind]
}
}
units$units <- data_units
return(units)
}
# 3. LOAD DATA -----
# Load site data from first site when app initalizies
site <- sites[1]
data <- read_data_all_years(basepath,site,level,tv_input)
data_units <- var_units(colnames(data),UnitCSVFilePath)
ylabel <- paste0(dat_names, ' (', data_units$units[which(data_units$name == dat_names)], ')')
ylabel
runApp('~/Code/shiny_test/load_data_shiny.R')
# 1. SET UP  -----
# Load libraries
library(dplyr)
library(ggplot2)
library(shiny)
library(patchwork)
library(plotly)
library(gapminder)
library(shinycssloaders)
library(readxl)
library(stringi)
library(shinythemes)
library(cowplot)
library(imager) # had to download quartz to be able to run this library properly (https://www.xquartz.org) & may need to use install.packages("igraph", type="binary")
library(naniar)
library(GGally)
library(shinydashboard)
library(tidyr)
library(tibble)
library(epitools)
library(lubridate)
library(hms)
# reactiveConsole(T) # allows the csv file to be used properly
# “install.packages(“igraph”, type=“binary”) - uncomment if receiving a “there is no package called ‘igraph’” error when loading imager
main_dir <- "/Users/saraknox/Code/local_data_cleaning/Database"
setwd(main_dir)
# List all directories and subdirectories
dir_list <- list.dirs(main_dir,full.names = TRUE,
recursive = TRUE)
# From that list, get site names
dir_length <- lengths(strsplit(dir_list, "/"))
dir_sites <- dir_list[dir_length == max(dir_length)-4 & grepl("[[:digit:]]", dir_list) == TRUE]
sites <- unique(sapply(strsplit(dir_sites, "/"), '[[', 8))
basepath <- main_dir
level <- "Clean/SecondStage"
tv_input <- "clean_tv"
UnitCSVFilePath <- '/Users/saraknox/Code/shiny_test/flux_variables.csv'
# 2. FUNCTIONS -----
read_data_all_years <-
function(basepath,
site,
level,
tv_input,
variables,
export,
outpath,
outfilename) {
# Load libraries
library(reshape2)
library(stringr)
library(lubridate)
# Find which years are available
dir_yrs_sites <- dir_sites[grepl(site, dir_sites) == TRUE]
yrs <- unique(sapply(strsplit(dir_yrs_sites, "/"), '[[', 7))
# Loop through years
for (i in 1:length(yrs)) {
inpath <-
paste(basepath,
"/",
as.character(yrs[i]),
"/",
site,
"/",
level[1],
sep = "")
#setwd()
#Convert Matlab timevector to POSIXct
tv <- readBin(paste0(inpath,"/",tv_input,sep=""), double(), n = 18000)
datetime <-
as.POSIXct((tv - 719529) * 86400, origin = "1970-01-01", tz = "UTC")
# Round to nearest 30 min
datetime <- lubridate::round_date(datetime, "30 minutes")
#setup empty dataframe
frame <- data.frame(matrix(ncol = 1, nrow = length(datetime)))
# Loop through levels
for (j in 1:length(level)) {
inpath <-
paste(basepath,
"/",
as.character(yrs[i]),
"/",
site,
"/",
level[j],
sep = "")
#Extract data of interest
##Use a loop function to read selected binary files and bind to the empty dataframe
# if variables not defined
if( !is.null("variables") )
{
variables <- list.files(paste0(inpath,"/"))
}
for (k in 1:length(variables)) {
if (variables[k] %in% list.files(inpath)) {
# If the variable is included in the current level
# Skip the data_EP.txt file
if (grepl(".txt$", variables[k])) next
if (grepl("clean_tv", variables[k])) next
data <-
data.frame(readBin(paste0(inpath,"/",variables[k],sep=""), numeric(), n = 18000, size = 4))
colnames(data) <- variables[k]
frame <- cbind(frame, data)
}
}
}
df <-
subset(frame, select = -c(1)) #remove the first column that does not contain information
df <- cbind(datetime, df) #Combine data with datetime
# Make sure all input variables are included in the dataframe
if (sum(which(variables %in% colnames(df) == FALSE)) > 0) {
cat("variables: ", variables[which(variables %in% colnames(df) == FALSE)],"are not included in the dataframe", sep="\n")
}
if (i == 1) {
empty_df = df[FALSE, ]
dfmultiyear <- rbind(empty_df, df)
} else {
dfmultiyear <- rbind(dfmultiyear, df)
}
}
if( !is.null("export") ){
export <- 0
}
if (export == 1) {
write.csv(df, paste(outpath, outfilename, ".csv", sep = ""))
}
return(dfmultiyear)
}
var_units <- function(Variables, UnitCSVFilePath) {
# -------------------------------------------------------------------------- #
# ARGUMENTS:
# - Variables [list]: list of variable names
# - UnitCSVFilePath [str]: A string that contains the path to an AmeriFlux
#   CSV
# PURPOSE:
# - matches user-inputted variables to their AmeriFlux Variable and Units
#   counterparts.
# OUTPUT:
# - returns a dataframe containing the AmeriFlux Varaibles and Units data
#   adhering to the user-inputted csv's.
# -------------------------------------------------------------------------- #
shortnames <- sapply(strsplit(Variables, split = "(_[0-9])"), '[',1)
shortnames <- sapply(strsplit(shortnames, split = "_PI"),'[',1)
units <- data.frame(name = Variables,
variable = shortnames)
flux_var <- read.csv(UnitCSVFilePath)
flux_var <- flux_var[, c('Variable',
'Units',
'Type')]
for (i in 1:length(units$variable)) {
units$variable[i] <- stringr::str_to_upper(units$variable[i])
}
data_units <- vector(mode='character',length=length(units$variable))
for (i in 1:length(units$variable)) {
if (length(which(flux_var$Variable %in% units$variable[i])) > 0) {
ind <- which(flux_var$Variable %in% units$variable[i])
data_units[i] <- flux_var$Units[ind]
}
}
units$units <- data_units
return(units)
}
# 3. LOAD DATA -----
# Load site data from first site when app initalizies
site <- sites[1]
data <- read_data_all_years(basepath,site,level,tv_input)
data_units <- var_units(colnames(data),UnitCSVFilePath)
# 4. USER INTERFACE ----
ui <- dashboardPage(skin = 'black', # Begin UI
dashboardHeader(title = "CARBONIQUE Data Visualization"),
dashboardSidebar(sidebarMenu(
menuItem("Individual sites", tabName = "indiv"),
menuItem("All sites", tabName = "all"),
menuItem("About", tabName = "about")
)), # End dashboard sidebar
dashboardBody( # Begin dashboard body
# Suppress warnings
tags$style(type="text/css",
".shiny-output-error { visibility: hidden; }",
".shiny-output-error:before { visibility: hidden; }"),
tabItems(
tabItem( # Begin 'Individual Sites' page
h1('Individual sites'),
tabName = "indiv",
# Select site from dropdown list
selectInput('sites', 'Select site', sites,
multiple = F),
# 1. Site information (main panel)
br(), br(),
tabsetPanel( # Begin tab panels section
tabPanel( # Begin time series tab
"Time series",
br(),
# Select main variable
fluidRow( column(6, selectInput('tscol', 'Variable', names(data[-c(1)]))),
# Select date range for time series
column(12,  sliderInput(inputId = "range", width = '80%',
label = "Date range",
min = min(data$datetime, na.rm = T),
max = max(data$datetime, na.rm = T),
value = c(min(data$datetime, na.rm = T),
max(data$datetime, na.rm = T))))),
br(),
# Ouput time series plot with a spinner
shinycssloaders::withSpinner(plotlyOutput('timeseries_plots'),
type = getOption("spinner.type", default = 5),
color = getOption("spinner.color", default = "#4D90FE")),
h5(em('Plot shows 30-min data'), align = 'center')
), # End time series tab
tabPanel('Diurnal Cycle',
# CREATE VARIABLE INPUTS
fluidRow(column(6, selectInput('dicol', 'Variable', names(data[-c(1)])))
), # END FLUID ROW
# OUTPUT DIURNAL PLOTS (W/ SPINNER)
shinycssloaders::withSpinner(plotlyOutput('diurnal',
width = '100%', height = '60%'),
type = getOption("spinner.type", default = 5),
color = getOption("spinner.color", default = "dodgerblue")),
br(),
h5(em('Plot shows mean (black line) and +- one standard deviation (shading) of half-hourly data by month.'),
align = 'center')
) # END DIURNAL CYCLE TAB
)
)
)
)
)
server <- function(input, output, session) { # Begin server
observeEvent(input$sites, { # Change output based on site selection
# Update data
data <- read_data_all_years(basepath,input$sites,level,tv_input)
data_units <- var_units(colnames(data),UnitCSVFilePath)
sitename <- input$sites
# Update Y variable (time series)
updateSelectInput(session, 'tscol', choices = names(data[-c(1)]))
# Update Y variable (diurnal)
updateSelectInput(session, 'dicol', choices = names(data[-c(1)]))
# Update time series limits
updateSliderInput(inputId = "range",
min = min(data$datetime, na.rm = T),
max = max(data$datetime, na.rm = T),
value = c(min(data$datetime, na.rm = T),
max(data$datetime, na.rm = T)))
# Select data for plots based on user inputs
selectedData <- reactive({ # Time series plots
data[, c(input$tscol)]
})
selectedDataDiurnal <- reactive({ # Diurnal plots
data[, c(input$dicol)]
})
# OUTPUTS:  -----
# a) Time series plots
output$timeseries_plots <- renderPlotly({
dat_names <- names(selectedData()) # Get name of variable selected
ylabel <- dat_names#paste0(dat_names, ' (', data_units$units[which(data_units$name == dat_names)], ')')
Value <- selectedData()#[,1] # Data from variable
Date <- data$datetime # Date data
p1 <- ggplot() +
geom_line(aes(x = Date,
y = Value),
na.rm = T, col = '#B21B00') + # color of line
theme_bw() + # plot theme
theme(text=element_text(size=20), #change font size of all text
axis.text=element_text(size=15), #change font size of axis text
axis.title=element_text(size=12), #change font size of axis titles
plot.title=element_text(size=20), #change font size of plot title
legend.text=element_text(size=15), #change font size of legend text
legend.title=element_text(size=15),
plot.margin = margin(t = 20,  # Top margin
r = 30,  # Right margin
b = 30,  # Bottom margin
l = 30)) + # Left margin +
ylab(ylabel) +
xlab('Date')  + # relabl X axis
xlim(input$range[1], input$range[2]) # change date limits to user input
p1 <- ggplotly(p1) # create plotly
})
# b) Diurnal plot
output$diurnal <- renderPlotly({
DataDiurnal <- data.frame(data$datetime)
colnames(DataDiurnal) <- 'datetime'
DataDiurnal$Month <- as.numeric(substring(data$datetime, 6, 7))
DataDiurnal$Hour <- format(data$datetime, format = "%H%M")
DataDiurnal$Var <- selectedDataDiurnal()
data_diurnal <- DataDiurnal %>% group_by(Month, Hour) %>% summarise(Average = mean(Var, na.rm=TRUE))
data_diurnal$Hour <- as.numeric(data_diurnal$Hour)
var_sd <- sd(data_diurnal$Average, na.rm = TRUE)
data_diurnal$UppSD <- data_diurnal$Average + var_sd
data_diurnal$LowSD <- data_diurnal$Average - var_sd
month_labs <- c('1' = 'January', '2' = 'February', '3' = 'March',
'4' = 'April', '5' = 'May', '6' = 'June',
'7' = 'July', '8' = 'August', '9' = 'September',
'10' = 'October', '11' = 'November', '12' = 'December')
month_labeller <- labeller(Month = function(levels) month_labs[as.character(levels)])
diurnal_plot <- ggplot(data = data_diurnal,
aes(x = Hour, y = Average)) +
geom_line() +
geom_ribbon(aes(ymax = UppSD, ymin = LowSD),
col = 'dodgerblue4', fill = 'dodgerblue4', alpha = 0.3) +
facet_wrap(~ Month, ncol = 4,
labeller = month_labeller) +
scale_x_continuous(breaks = c(0, 600, 1200, 1800, 2330),
labels = c("00:00", "06:00", "12:00", "18:00","24:00")) +
scale_y_continuous(limits = c(min(data_diurnal$LowSD),
max(data_diurnal$UppSD))) +
theme_minimal()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
xlab("Hour:Minute")#+#,
#y = paste(input$di_var, " [", DiUnits()[1], "]")) +
theme(panel.spacing.x = unit(3, "mm"),
panel.spacing.y = unit(6, "mm"),
strip.placement = "outside",
strip.background = element_blank())
ggplotly(diurnal_plot)  # Set tooltip to display the custom text
}) # End plot render
})
}# End server
# 6. RUN APP -----
shinyApp(ui = ui, server = server)
runApp('~/Code/shiny_test/load_data_shiny.R')
runApp('~/Code/shiny_test/load_data_shiny.R')
runApp('~/Code/shiny_test/load_data_shiny.R')
colnames(data[,1])
colnames(data[1,])
colnames(data)[1]
runApp('~/Code/shiny_test/load_data_shiny.R')
runApp('~/Code/shiny_test/load_data_shiny.R')
runApp('~/Code/shiny_test/load_data_shiny.R')
runApp('~/Code/shiny_test/load_data_shiny.R')
runApp('~/Code/shiny_test/load_data_shiny.R')
library(shiny); runApp('load_data_shiny.R')
library(shiny); runApp('load_data_shiny.R')
runApp('load_data_shiny.R')
runApp('load_data_shiny.R')
library(shiny); runApp('load_data_shiny.R')
