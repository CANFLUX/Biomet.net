{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading & Writing to the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORG_Field1 config file does not exist. Skpping\n",
      "ORG_Field2 config file does not exist. Skpping\n",
      "ORG_Field1 config file does not exist. Skpping\n",
      "ORG_Field2 config file does not exist. Skpping\n",
      "biomet Write_Biomet_CSV.json\n",
      "Creating biomet .csv files for BBS\n",
      "ffp Write_FFP_Input_CSV.json\n",
      "Creating ffp .csv files for BBS\n"
     ]
    }
   ],
   "source": [
    "import DatabaseFunctions\n",
    "import importlib\n",
    "import time\n",
    "importlib.reload(DatabaseFunctions)\n",
    "\n",
    "# The \"Super\" class upon which the other application are built\n",
    "# Won't need to directly call this as its looped into whichever application you're using\n",
    "DBF = DatabaseFunctions.DatabaseFunctions()\n",
    "# print('Data-Years by Site')\n",
    "# DBF.years_by_site\n",
    "\n",
    "# # Given an ini file with a request, can create database traces from input files (e.g., .dat, .csv, etc.)\n",
    "# WD = DatabaseFunctions.MakeTraces(ini='ini_files/WriteTraces.ini')\n",
    "\n",
    "# # Given an ini file with a request, can create database traces from google sheets\n",
    "# # Good for manual data collected in the field (e.g. manaul WTD data)\n",
    "# # Assumes local (daylight/standard) time, will auto convert to local standard time\n",
    "# WG = DatabaseFunctions.GSheetDump(ini='ini_files/WriteTraces_Gsheets.ini')\n",
    "\n",
    "# # Given an ini file with a request, can create .csv files from database traces\n",
    "# # By default will process request for each site/year\n",
    "# # Passing Sites =['BB','BB2'] or Years = [2022,2023] etc. can be used to restrict request\n",
    "RD = DatabaseFunctions.MakeCSV(Sites = ['BBS'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_path': 'HIGHFREQ/footprint/',\n",
       " 'by_year': 'False',\n",
       " 'stage': 'Clean/SecondStage/',\n",
       " 'traces': 'L,USTAR,wind_speed,wind_dir,V_SIGMA,canopy_height,hpbl',\n",
       " 'units': 'm,m s^-1,m s^-1,deg,m s^-1,m,m',\n",
       " 'timestamp': 'TIMESTAMP',\n",
       " 'timestamp_fmt': '%Y-%m-%d %H%M',\n",
       " 'timestamp_units': 'yyyy-mm-dd HHMM',\n",
       " 'units_in_header': 'False',\n",
       " 'rename': ''}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import configparser\n",
    "\n",
    "conf = configparser.ConfigParser()\n",
    "conf.read('ini_files/Write_CSV_Files.ini')\n",
    "\n",
    "Biom = dict(conf['FFP_Inputs'])\n",
    "\n",
    "Trace_Deffs = {'Traces':{}}\n",
    "# for in_name,out_name,units in zip(Biom['traces'].split(','),Biom['rename'].split(','),Biom['units'].split(',')):\n",
    "for in_name,units in zip(Biom['traces'].split(','),Biom['units'].split(',')):\n",
    "    Trace_Deffs['Traces'][in_name] = {'Units':units,'output_name':in_name}\n",
    "Trace_Deffs['timestamp'] = {'timestamp_fmt':Biom['timestamp_fmt'],'timestamp_units':Biom['timestamp_units'],'output_name':Biom['timestamp']}\n",
    "for i in [ 'units_in_header','output_path','by_year','stage']:\n",
    "    Trace_Deffs[i] = Biom[i]\n",
    "Trace_Deffs['na_value'] = 'np.nan'\n",
    "Trace_Deffs['filename'] = 'np.nan'\n",
    "# Biom\n",
    "with open('ini_files/Write_FFP_Input_CSV.json', 'w') as f:\n",
    "    json.dump(Trace_Deffs, f,indent=2)\n",
    "\n",
    "# with open('ini_files/Write_Biomet_CSV.json') as jsonfile:\n",
    "#     # `json.loads` parses a string in json format\n",
    "#     Trace_Deffs = json.load(jsonfile)\n",
    "Biom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading NARR \n",
    "\n",
    "* Can expand to ECCC Data and various other products if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating hpbl for 2021 at DM\n",
      "Estimating hpbl for 2021 at NFB\n",
      "Estimating hpbl for 2021 at NM\n",
      "Estimating hpbl for 2021 at NOB\n",
      "Estimating hpbl for 2021 at NS\n",
      "Estimating hpbl for 2021 at RM\n",
      "Estimating hpbl for 2022 at DM\n",
      "Estimating hpbl for 2022 at NFB\n",
      "Estimating hpbl for 2022 at NM\n",
      "Estimating hpbl for 2022 at NOB\n",
      "Estimating hpbl for 2022 at NS\n",
      "Estimating hpbl for 2022 at RM\n",
      "Estimating hpbl for 2023 at DM\n",
      "Estimating hpbl for 2023 at NFB\n",
      "Estimating hpbl for 2023 at NM\n",
      "Estimating hpbl for 2023 at NOB\n",
      "Estimating hpbl for 2023 at NS\n",
      "Estimating hpbl for 2023 at RM\n",
      "95.2293050289154\n"
     ]
    }
   ],
   "source": [
    "import ExtractNARR\n",
    "import importlib\n",
    "import time\n",
    "importlib.reload(ExtractNARR)\n",
    "T1 = time.time()\n",
    "EX = ExtractNARR.PointSample([2021,2022,2023],Limit_to_Sites=['DM','RM','NM','NS','NOB','NFB'])\n",
    "print(time.time()-T1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTC input:\n",
      "DatetimeIndex(['2023-03-11 23:00:00', '2023-03-12 00:00:00',\n",
      "               '2023-03-12 01:00:00', '2023-03-12 02:00:00',\n",
      "               '2023-03-12 03:00:00', '2023-03-12 04:00:00',\n",
      "               '2023-03-12 05:00:00', '2023-03-12 06:00:00',\n",
      "               '2023-03-12 07:00:00', '2023-03-12 08:00:00'],\n",
      "              dtype='datetime64[ns]', freq='H')\n",
      "Standard Time (non-TZ aware):\n",
      "DatetimeIndex(['2023-03-12 07:00:00', '2023-03-12 08:00:00',\n",
      "               '2023-03-12 09:00:00', '2023-03-12 10:00:00',\n",
      "               '2023-03-12 11:00:00', '2023-03-12 12:00:00',\n",
      "               '2023-03-12 13:00:00', '2023-03-12 14:00:00',\n",
      "               '2023-03-12 15:00:00', '2023-03-12 16:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "Local Time (TZ aware):\n",
      "DatetimeIndex(['2023-03-11 23:00:00+00:00', '2023-03-12 00:00:00+00:00',\n",
      "               '2023-03-12 01:00:00+00:00', '2023-03-12 02:00:00+00:00',\n",
      "               '2023-03-12 03:00:00+00:00', '2023-03-12 04:00:00+00:00',\n",
      "               '2023-03-12 05:00:00+00:00', '2023-03-12 06:00:00+00:00',\n",
      "               '2023-03-12 07:00:00+00:00', '2023-03-12 08:00:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', freq=None)\n",
      "UTC Time (TZ aware):\n",
      "DatetimeIndex(['2023-03-12 07:00:00+08:00', '2023-03-12 08:00:00+08:00',\n",
      "               '2023-03-12 09:00:00+08:00', '2023-03-12 10:00:00+08:00',\n",
      "               '2023-03-12 11:00:00+08:00', '2023-03-12 12:00:00+08:00',\n",
      "               '2023-03-12 13:00:00+08:00', '2023-03-12 14:00:00+08:00',\n",
      "               '2023-03-12 15:00:00+08:00', '2023-03-12 16:00:00+08:00'],\n",
      "              dtype='datetime64[ns, Etc/GMT-8]', freq=None)\n",
      "UTC input:\n",
      "DatetimeIndex(['2023-03-11 23:00:00', '2023-03-12 00:00:00',\n",
      "               '2023-03-12 01:00:00', '2023-03-12 02:00:00',\n",
      "               '2023-03-12 03:00:00', '2023-03-12 04:00:00',\n",
      "               '2023-03-12 05:00:00', '2023-03-12 06:00:00',\n",
      "               '2023-03-12 07:00:00', '2023-03-12 08:00:00'],\n",
      "              dtype='datetime64[ns]', freq='H')\n",
      "Standard Time (non-TZ aware):\n",
      "DatetimeIndex(['2023-03-11 15:00:00', '2023-03-11 16:00:00',\n",
      "               '2023-03-11 17:00:00', '2023-03-11 18:00:00',\n",
      "               '2023-03-11 19:00:00', '2023-03-11 20:00:00',\n",
      "               '2023-03-11 21:00:00', '2023-03-11 22:00:00',\n",
      "               '2023-03-11 23:00:00', '2023-03-12 00:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "Local Time (TZ aware):\n",
      "DatetimeIndex(['2023-03-11 23:00:00+00:00', '2023-03-12 00:00:00+00:00',\n",
      "               '2023-03-12 01:00:00+00:00', '2023-03-12 02:00:00+00:00',\n",
      "               '2023-03-12 03:00:00+00:00', '2023-03-12 04:00:00+00:00',\n",
      "               '2023-03-12 05:00:00+00:00', '2023-03-12 06:00:00+00:00',\n",
      "               '2023-03-12 07:00:00+00:00', '2023-03-12 08:00:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', freq=None)\n",
      "UTC Time (TZ aware):\n",
      "DatetimeIndex(['2023-03-11 15:00:00-08:00', '2023-03-11 16:00:00-08:00',\n",
      "               '2023-03-11 17:00:00-08:00', '2023-03-11 18:00:00-08:00',\n",
      "               '2023-03-11 19:00:00-08:00', '2023-03-11 20:00:00-08:00',\n",
      "               '2023-03-11 21:00:00-08:00', '2023-03-11 22:00:00-08:00',\n",
      "               '2023-03-11 23:00:00-08:00', '2023-03-12 00:00:00-08:00'],\n",
      "              dtype='datetime64[ns, America/Vancouver]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "import TzFuncs\n",
    "import importlib\n",
    "import pandas as pd\n",
    "importlib.reload(TzFuncs)\n",
    "\n",
    "# Convert FROM UTC\n",
    "input = pd.date_range(start='2023-03-11 23:00',end='2023-03-12 08:00',freq='1H')\n",
    "tzf = TzFuncs.Tzfuncs(Time_Zone='Etc/GMT-8')\n",
    "tzf.convert(input,from_UTC=True)\n",
    "print('UTC input:')\n",
    "print(input)\n",
    "print('Standard Time (non-TZ aware):')\n",
    "print(tzf.Standard_Time)\n",
    "print('Local Time (TZ aware):')\n",
    "print(tzf.UTC_Time)\n",
    "print('UTC Time (TZ aware):')\n",
    "print(tzf.Local_Time)\n",
    "\n",
    "# Convert FROM America/Vancouver (DST) to standard time & UTC time\n",
    "input = pd.date_range(start='2023-03-11 23:00',end='2023-03-12 08:00',freq='1H')\n",
    "tzf = TzFuncs.Tzfuncs(Time_Zone='America/Vancouver',DST=True)\n",
    "tzf.convert(input,to_UTC=True)\n",
    "print('America/Vancouver input:')\n",
    "print(input)\n",
    "print('Standard Time (non-TZ aware):')\n",
    "print(tzf.Standard_Time)\n",
    "print('Local Time (TZ & DST aware):')\n",
    "print(tzf.UTC_Time)\n",
    "print('UTC Time (TZ aware):')\n",
    "print(tzf.Local_Time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a spatial config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating site config for BB from Y:/BB/raw/2023/01/2023-01-01T083000_LI-7200.ghg\n",
      "Creating site config for BB2 from Y:/BB2/raw/2023/01/2023-01-01T013000_AIU-1696.ghg\n",
      "Creating site config for DSM from Y:/DSM/raw/2023/01/2023-01-01T053000_AIU-2264.ghg\n",
      "Creating site config for RBM from Y:/RBM/raw/2023/01/2023-01-01T030000_AIU-1292.ghg\n",
      "Creating site config for HOGG from Y:/HOGG/raw/2023/01/2023-01-01T063000_smart3-00494.ghg\n",
      "Creating site config for YOUNG from Y:/YOUNG/raw/2023/01/2023-01-01T043000_smart3-00495.ghg\n",
      "Creating site config for OHM from Y:/OHM/raw/2023/06/2023-06-06T200000_smart3-00820.ghg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import importlib\n",
    "import MakeSpatialConfigFile\n",
    "importlib.reload(MakeSpatialConfigFile)\n",
    "\n",
    "for site,start_year in zip(['BB','BB2','DSM','RBM','HOGG','YOUNG'],\n",
    "                            [2015,2019,2021,2022,2021,2020]):\n",
    "    root = f'Y:/{site}/raw/2023/01/'\n",
    "    out = f'Y:/{site}/footprint/'\n",
    "    for file in os.listdir(root):\n",
    "        if file.endswith('.ghg'):\n",
    "            print(f'Creating site config for {site} from {root+file}')\n",
    "            MakeSpatialConfigFile.from_GHG(site,root+file,start_year,out)\n",
    "            break\n",
    "\n",
    "\n",
    "for site,start_year in zip(['OHM'],\n",
    "                           [2023]):\n",
    "    root = f'Y:/{site}/raw/2023/06/'\n",
    "    out = f'Y:/{site}/footprint/'\n",
    "    for file in os.listdir(root):\n",
    "        if file.endswith('.ghg'):\n",
    "            print(f'Creating site config for {site} from {root+file}')\n",
    "            MakeSpatialConfigFile.from_GHG(site,root+file,start_year,out)\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
