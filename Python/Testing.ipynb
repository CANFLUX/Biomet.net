{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading & Writing to the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORG_Field1 config file does not exist. Skpping\n",
      "ORG_Field2 config file does not exist. Skpping\n",
      "ORG_Field1 config file does not exist. Skpping\n",
      "ORG_Field2 config file does not exist. Skpping\n",
      "biomet Write_Biomet_CSV.json\n",
      "Creating biomet .csv files for BBS\n",
      "ffp Write_FFP_Input_CSV.json\n",
      "Creating ffp .csv files for BBS\n"
     ]
    }
   ],
   "source": [
    "import DatabaseFunctions\n",
    "import importlib\n",
    "import time\n",
    "importlib.reload(DatabaseFunctions)\n",
    "\n",
    "# The \"Super\" class upon which the other application are built\n",
    "# Won't need to directly call this as its looped into whichever application you're using\n",
    "DBF = DatabaseFunctions.DatabaseFunctions()\n",
    "# print('Data-Years by Site')\n",
    "# DBF.years_by_site\n",
    "\n",
    "# # Given an ini file with a request, can create database traces from input files (e.g., .dat, .csv, etc.)\n",
    "# WD = DatabaseFunctions.MakeTraces(ini='ini_files/WriteTraces.ini')\n",
    "\n",
    "# # Given an ini file with a request, can create database traces from google sheets\n",
    "# # Good for manual data collected in the field (e.g. manaul WTD data)\n",
    "# # Assumes local (daylight/standard) time, will auto convert to local standard time\n",
    "# WG = DatabaseFunctions.GSheetDump(ini='ini_files/WriteTraces_Gsheets.ini')\n",
    "\n",
    "# # Given an ini file with a request, can create .csv files from database traces\n",
    "# # By default will process request for each site/year\n",
    "# # Passing Sites =['BB','BB2'] or Years = [2022,2023] etc. can be used to restrict request\n",
    "RD = DatabaseFunctions.MakeCSV(Sites = ['BBS'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_path': 'HIGHFREQ/footprint/',\n",
       " 'by_year': 'False',\n",
       " 'stage': 'Clean/SecondStage/',\n",
       " 'traces': 'L,USTAR,wind_speed,wind_dir,V_SIGMA,canopy_height,hpbl',\n",
       " 'units': 'm,m s^-1,m s^-1,deg,m s^-1,m,m',\n",
       " 'timestamp': 'TIMESTAMP',\n",
       " 'timestamp_fmt': '%Y-%m-%d %H%M',\n",
       " 'timestamp_units': 'yyyy-mm-dd HHMM',\n",
       " 'units_in_header': 'False',\n",
       " 'rename': ''}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import configparser\n",
    "\n",
    "conf = configparser.ConfigParser()\n",
    "conf.read('ini_files/Write_CSV_Files.ini')\n",
    "\n",
    "Biom = dict(conf['FFP_Inputs'])\n",
    "\n",
    "Trace_Deffs = {'Traces':{}}\n",
    "# for in_name,out_name,units in zip(Biom['traces'].split(','),Biom['rename'].split(','),Biom['units'].split(',')):\n",
    "for in_name,units in zip(Biom['traces'].split(','),Biom['units'].split(',')):\n",
    "    Trace_Deffs['Traces'][in_name] = {'Units':units,'output_name':in_name}\n",
    "Trace_Deffs['timestamp'] = {'timestamp_fmt':Biom['timestamp_fmt'],'timestamp_units':Biom['timestamp_units'],'output_name':Biom['timestamp']}\n",
    "for i in [ 'units_in_header','output_path','by_year','stage']:\n",
    "    Trace_Deffs[i] = Biom[i]\n",
    "Trace_Deffs['na_value'] = 'np.nan'\n",
    "Trace_Deffs['filename'] = 'np.nan'\n",
    "# Biom\n",
    "with open('ini_files/Write_FFP_Input_CSV.json', 'w') as f:\n",
    "    json.dump(Trace_Deffs, f,indent=2)\n",
    "\n",
    "# with open('ini_files/Write_Biomet_CSV.json') as jsonfile:\n",
    "#     # `json.loads` parses a string in json format\n",
    "#     Trace_Deffs = json.load(jsonfile)\n",
    "Biom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading NARR \n",
    "\n",
    "* Can expand to ECCC Data and various other products if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating hpbl for 2021 at DM\n",
      "Estimating hpbl for 2021 at NFB\n",
      "Estimating hpbl for 2021 at NM\n",
      "Estimating hpbl for 2021 at NOB\n",
      "Estimating hpbl for 2021 at NS\n",
      "Estimating hpbl for 2021 at RM\n",
      "Estimating hpbl for 2022 at DM\n",
      "Estimating hpbl for 2022 at NFB\n",
      "Estimating hpbl for 2022 at NM\n",
      "Estimating hpbl for 2022 at NOB\n",
      "Estimating hpbl for 2022 at NS\n",
      "Estimating hpbl for 2022 at RM\n",
      "Estimating hpbl for 2023 at DM\n",
      "Estimating hpbl for 2023 at NFB\n",
      "Estimating hpbl for 2023 at NM\n",
      "Estimating hpbl for 2023 at NOB\n",
      "Estimating hpbl for 2023 at NS\n",
      "Estimating hpbl for 2023 at RM\n",
      "95.2293050289154\n"
     ]
    }
   ],
   "source": [
    "import ExtractNARR\n",
    "import importlib\n",
    "import time\n",
    "importlib.reload(ExtractNARR)\n",
    "T1 = time.time()\n",
    "EX = ExtractNARR.PointSample([2021,2022,2023],Limit_to_Sites=['DM','RM','NM','NS','NOB','NFB'])\n",
    "print(time.time()-T1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTC input:\n",
      "DatetimeIndex(['2023-03-11 23:00:00', '2023-03-12 00:00:00',\n",
      "               '2023-03-12 01:00:00', '2023-03-12 02:00:00',\n",
      "               '2023-03-12 03:00:00', '2023-03-12 04:00:00',\n",
      "               '2023-03-12 05:00:00', '2023-03-12 06:00:00',\n",
      "               '2023-03-12 07:00:00', '2023-03-12 08:00:00'],\n",
      "              dtype='datetime64[ns]', freq='H')\n",
      "Standard Time (non-TZ aware):\n",
      "DatetimeIndex(['2023-03-12 07:00:00', '2023-03-12 08:00:00',\n",
      "               '2023-03-12 09:00:00', '2023-03-12 10:00:00',\n",
      "               '2023-03-12 11:00:00', '2023-03-12 12:00:00',\n",
      "               '2023-03-12 13:00:00', '2023-03-12 14:00:00',\n",
      "               '2023-03-12 15:00:00', '2023-03-12 16:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "Local Time (TZ aware):\n",
      "DatetimeIndex(['2023-03-11 23:00:00+00:00', '2023-03-12 00:00:00+00:00',\n",
      "               '2023-03-12 01:00:00+00:00', '2023-03-12 02:00:00+00:00',\n",
      "               '2023-03-12 03:00:00+00:00', '2023-03-12 04:00:00+00:00',\n",
      "               '2023-03-12 05:00:00+00:00', '2023-03-12 06:00:00+00:00',\n",
      "               '2023-03-12 07:00:00+00:00', '2023-03-12 08:00:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', freq=None)\n",
      "UTC Time (TZ aware):\n",
      "DatetimeIndex(['2023-03-12 07:00:00+08:00', '2023-03-12 08:00:00+08:00',\n",
      "               '2023-03-12 09:00:00+08:00', '2023-03-12 10:00:00+08:00',\n",
      "               '2023-03-12 11:00:00+08:00', '2023-03-12 12:00:00+08:00',\n",
      "               '2023-03-12 13:00:00+08:00', '2023-03-12 14:00:00+08:00',\n",
      "               '2023-03-12 15:00:00+08:00', '2023-03-12 16:00:00+08:00'],\n",
      "              dtype='datetime64[ns, Etc/GMT-8]', freq=None)\n",
      "UTC input:\n",
      "DatetimeIndex(['2023-03-11 23:00:00', '2023-03-12 00:00:00',\n",
      "               '2023-03-12 01:00:00', '2023-03-12 02:00:00',\n",
      "               '2023-03-12 03:00:00', '2023-03-12 04:00:00',\n",
      "               '2023-03-12 05:00:00', '2023-03-12 06:00:00',\n",
      "               '2023-03-12 07:00:00', '2023-03-12 08:00:00'],\n",
      "              dtype='datetime64[ns]', freq='H')\n",
      "Standard Time (non-TZ aware):\n",
      "DatetimeIndex(['2023-03-11 15:00:00', '2023-03-11 16:00:00',\n",
      "               '2023-03-11 17:00:00', '2023-03-11 18:00:00',\n",
      "               '2023-03-11 19:00:00', '2023-03-11 20:00:00',\n",
      "               '2023-03-11 21:00:00', '2023-03-11 22:00:00',\n",
      "               '2023-03-11 23:00:00', '2023-03-12 00:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "Local Time (TZ aware):\n",
      "DatetimeIndex(['2023-03-11 23:00:00+00:00', '2023-03-12 00:00:00+00:00',\n",
      "               '2023-03-12 01:00:00+00:00', '2023-03-12 02:00:00+00:00',\n",
      "               '2023-03-12 03:00:00+00:00', '2023-03-12 04:00:00+00:00',\n",
      "               '2023-03-12 05:00:00+00:00', '2023-03-12 06:00:00+00:00',\n",
      "               '2023-03-12 07:00:00+00:00', '2023-03-12 08:00:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', freq=None)\n",
      "UTC Time (TZ aware):\n",
      "DatetimeIndex(['2023-03-11 15:00:00-08:00', '2023-03-11 16:00:00-08:00',\n",
      "               '2023-03-11 17:00:00-08:00', '2023-03-11 18:00:00-08:00',\n",
      "               '2023-03-11 19:00:00-08:00', '2023-03-11 20:00:00-08:00',\n",
      "               '2023-03-11 21:00:00-08:00', '2023-03-11 22:00:00-08:00',\n",
      "               '2023-03-11 23:00:00-08:00', '2023-03-12 00:00:00-08:00'],\n",
      "              dtype='datetime64[ns, America/Vancouver]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "import TzFuncs\n",
    "import importlib\n",
    "import pandas as pd\n",
    "importlib.reload(TzFuncs)\n",
    "\n",
    "# Convert FROM UTC\n",
    "input = pd.date_range(start='2023-03-11 23:00',end='2023-03-12 08:00',freq='1H')\n",
    "tzf = TzFuncs.Tzfuncs(Time_Zone='Etc/GMT-8')\n",
    "tzf.convert(input,from_UTC=True)\n",
    "print('UTC input:')\n",
    "print(input)\n",
    "print('Standard Time (non-TZ aware):')\n",
    "print(tzf.Standard_Time)\n",
    "print('Local Time (TZ aware):')\n",
    "print(tzf.UTC_Time)\n",
    "print('UTC Time (TZ aware):')\n",
    "print(tzf.Local_Time)\n",
    "\n",
    "# Convert FROM America/Vancouver (DST) to standard time & UTC time\n",
    "input = pd.date_range(start='2023-03-11 23:00',end='2023-03-12 08:00',freq='1H')\n",
    "tzf = TzFuncs.Tzfuncs(Time_Zone='America/Vancouver',DST=True)\n",
    "tzf.convert(input,to_UTC=True)\n",
    "print('America/Vancouver input:')\n",
    "print(input)\n",
    "print('Standard Time (non-TZ aware):')\n",
    "print(tzf.Standard_Time)\n",
    "print('Local Time (TZ & DST aware):')\n",
    "print(tzf.UTC_Time)\n",
    "print('UTC Time (TZ aware):')\n",
    "print(tzf.Local_Time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a spatial config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating site config for BB from Y:/BB/raw/2023/01/2023-01-01T083000_LI-7200.ghg\n",
      "Creating site config for BB2 from Y:/BB2/raw/2023/01/2023-01-01T013000_AIU-1696.ghg\n",
      "Creating site config for DSM from Y:/DSM/raw/2023/01/2023-01-01T053000_AIU-2264.ghg\n",
      "Creating site config for RBM from Y:/RBM/raw/2023/01/2023-01-01T030000_AIU-1292.ghg\n",
      "Creating site config for HOGG from Y:/HOGG/raw/2023/01/2023-01-01T063000_smart3-00494.ghg\n",
      "Creating site config for YOUNG from Y:/YOUNG/raw/2023/01/2023-01-01T043000_smart3-00495.ghg\n",
      "Creating site config for OHM from Y:/OHM/raw/2023/06/2023-06-06T200000_smart3-00820.ghg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import importlib\n",
    "import MakeSpatialConfigFile\n",
    "importlib.reload(MakeSpatialConfigFile)\n",
    "\n",
    "for site,start_year in zip(['BB','BB2','DSM','RBM','HOGG','YOUNG'],\n",
    "                            [2015,2019,2021,2022,2021,2020]):\n",
    "    root = f'Y:/{site}/raw/2023/01/'\n",
    "    out = f'Y:/{site}/footprint/'\n",
    "    for file in os.listdir(root):\n",
    "        if file.endswith('.ghg'):\n",
    "            print(f'Creating site config for {site} from {root+file}')\n",
    "            MakeSpatialConfigFile.from_GHG(site,root+file,start_year,out)\n",
    "            break\n",
    "\n",
    "\n",
    "for site,start_year in zip(['OHM'],\n",
    "                           [2023]):\n",
    "    root = f'Y:/{site}/raw/2023/06/'\n",
    "    out = f'Y:/{site}/footprint/'\n",
    "    for file in os.listdir(root):\n",
    "        if file.endswith('.ghg'):\n",
    "            print(f'Creating site config for {site} from {root+file}')\n",
    "            MakeSpatialConfigFile.from_GHG(site,root+file,start_year,out)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "# To find database_default from inside (the root) of a project folder\n",
    "def get_matlab_default(fn=\"Matlab/biomet_database_default.m\"):\n",
    "    # Read .m file as \"text\"\n",
    "    with open(fn,encoding='utf8') as db:\n",
    "        config = db.read()\n",
    "        config = config.split('if ispc')[1].split('elseif ismac')\n",
    "        # Identify system, translate Matlab to Python, and evaluate\n",
    "        if sys.platform == 'win32':\n",
    "            exec(config[0].replace('%','#').replace(' ','').replace('\\\\','/'))\n",
    "        elif sys.platform == 'darwin':\n",
    "            exec(config[1].replace('%','#').replace(' ','').replace('\\\\','/'))\n",
    "    return(x)\n",
    "\n",
    "def get_config(fn='_config.yml'):\n",
    "    with open(fn) as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return(config['Database']['root'])\n",
    "\n",
    "os.chdir('C:/Users/User')\n",
    "\n",
    "config_fn = '_config.yml'\n",
    "matlab_fn = 'Matlab/biomet_database_default.m'\n",
    "\n",
    "# 1 Search for _config.yml in root of Project Folder\n",
    "if os.path.isfile(config_fn):\n",
    "    db_root = get_config(config_fn)\n",
    "\n",
    "# 2 Search for matalab default in root of project folder\n",
    "elif os.path.isfile(matlab_fn):\n",
    "    db_root = get_matlab_default(matlab_fn)\n",
    "\n",
    "# 3 Search environment variables for UBC_PC_Setup\n",
    "# Repeat 1 & 2, prompt for input as last resort\n",
    "else:\n",
    "    pth = [v for v in os.environ.values() if 'UBC_PC_Setup' in v]\n",
    "    if len(pth)>0:\n",
    "        if os.path.isfile(pth[0]+config_fn):\n",
    "            db_root = get_config(pth[0]+config_fn)\n",
    "        elif os.path.isfile(pth[0]+matlab_fn):\n",
    "            db_root = get_matlab_default(pth[0]+matlab_fn)\n",
    "    else:\n",
    "        db_root = input('No default database path found, input path to database:')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\UBC_PC_Setup\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'db_root' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdb_root\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdb\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m db\n",
      "File \u001b[1;32mC:\\Python310\\lib\\importlib\\__init__.py:169\u001b[0m, in \u001b[0;36mreload\u001b[1;34m(module)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspec not found for the module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m--> 169\u001b[0m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The module may have replaced itself in sys.modules!\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules[name]\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:619\u001b[0m, in \u001b[0;36m_exec\u001b[1;34m(spec, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Biomet.net\\Python\\db_root.py:53\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         db_root \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo default database path found, input path to database:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdb_root\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'db_root' is not defined"
     ]
    }
   ],
   "source": [
    "import db_root as db\n",
    "import importlib\n",
    "importlib.reload(db)\n",
    "\n",
    "db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# os.path.dirname(os.path.abspath(__file__))\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m script_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18;43m__file__\u001b[39;49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "# os.path.dirname(os.path.abspath(__file__))\n",
    "script_path = os.path.abspath(__file__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
